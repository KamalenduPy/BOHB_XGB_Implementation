# -*- coding: utf-8 -*-
"""BOHB_XGB.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1OMYoUJpyud1sB-jrwTmQwj4QdgYvUhpE
"""


import requests
import os
import hashlib
import tempfile
import gzip

import torch
import numpy as np

from bohb import BOHB
import bohb.configspace as cs

import pandas as pd

### Import the data


fish=pd.read_csv('/data/Fish.csv')


import requests
import os
import hashlib
import tempfile
import gzip

import torch
import numpy as np

from bohb import BOHB
import bohb.configspace as cs

from sklearn.ensemble import GradientBoostingClassifier

SEED = 123

def fetch_fish():
    idx = np.arange(0, 128+16)
    np.random.shuffle(idx)

    fish=pd.read_csv('Fish.csv')

    fish['Species']=fish['Species'].map({'Perch':0,'Bream':1,'Roach':2,'Pike':3,'Parkki':4,'Whitefish':5})

    X=fish.drop(['Species'],axis=1)
    Y=fish[['Species']]

    X_train = X.iloc[idx[:128]].to_numpy()
    Y_train = Y.iloc[idx[:128]].to_numpy().reshape(-1,)

    X_test = X.iloc[idx[128:]].to_numpy()
    Y_test = Y.iloc[idx[128:]].to_numpy().reshape(-1,)

    return X_train, Y_train, X_test, Y_test


def train_xgb(n_trees,learning_rate, max_depth,x_train, y_train, x_test, y_test,subsample):
    
    x_train, y_train, x_test, y_test = fetch_fish()
    import xgboost as xgb
    from sklearn.metrics import accuracy_score

    xgb_cl = xgb.XGBClassifier(x_train=x_train, y_train=y_train, x_test=x_test, y_test=y_test,subsample=subsample,
                n_trees=n_trees,learning_rate=learning_rate, max_depth=max_depth)
    model=xgb_cl.fit(x_train,y_train)
    y_pred=model.predict(x_test)
    loss = 1-(accuracy_score(y_test, y_pred))
    return loss

if __name__ == '__main__':
    np.random.seed(SEED)
    x_train, y_train, x_test, y_test = fetch_fish()

    def evaluate(params, budget):
        loss = train_xgb(**params, x_train=x_train, y_train=y_train,
                           x_test=x_test, y_test=y_test, subsample=(1-1/budget**2))
        
        return loss

    n_trees = cs.IntegerUniformHyperparameter('n_trees', lower=1,upper=20)
    max_depth = cs.IntegerUniformHyperparameter('max_depth', lower=1,upper=8)

    # optimizer = cs.CategoricalHyperparameter('optimizer', ['adam', 'sgd', 'rms'])
    learning_rate = cs.UniformHyperparameter('learning_rate', 1e-4, 1e-1, log=True)

    configspace = cs.ConfigurationSpace([n_trees, max_depth, learning_rate],
                                        seed=7)

    opt = BOHB(configspace, evaluate, max_budget=81, min_budget=1, n_proc=2)
    logs = opt.optimize()
    print(logs)





